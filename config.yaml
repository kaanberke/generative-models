# Checkpointing parameters
Checkpoint:
  dirpath: "checkpoints"
  save_top_k: 1
  filename: "model_{epoch:02d}_{val_generator_loss:.2f}"
  monitor: "val_generator_loss"
  mode: "min"
  verbose: true

# Trainer related parameters
Trainer:
  data_dir: "data/processed/thumbnails128x128"
  train_val_test_split: [0.8, 0.1, 0.1]
  lr: 3e-4
  factor: 0.2
  patience: 5
  verbose: True
  max_epochs: 50
  batch_size: 8
  image_size: 128
  accelerator: "mps" # cuda/cpu/mps
  num_sanity_val_steps: 0
  monitor: "val_generator_loss"
  mode: "min"

# Optimizer Params
Optimizer:
  name: "Adam"
  params:
    lr: 0.0003

Scheduler:
  name: "ReduceLROnPlateau"
  params:
    factor: 0.2
    patience: 5
    verbose: True
    mode: "min"


# VAE model-specific parameters
VAE:
  input_dimension: [3, 128, 128]  # [Channels, Width, Height]
  latent_dimension: 20

  # Encoder Convolutional Layers: [out_channels, kernel_size, stride, padding]
  encoder_conv_layers:
    - [32, 3, 2, 1]
    - [64, 3, 2, 1]
    - [128, 3, 2, 1]
    - [256, 3, 2, 1]

  # Decoder Deconvolutional Layers:
  # [out_channels, kernel_size, stride, padding]
  decoder_deconv_layers:
    - [128, 4, 2, 1]
    - [64, 4, 2, 1]
    - [32, 4, 2, 1]
    - [16, 4, 2, 1]
    - [8, 4, 2, 1]
    - [4, 4, 2, 1]
    - [3, 4, 2, 1]


GAN:
  latent_dim: 100  # Size of the random noise vector for the generator

  generator_layers:
    - 100  # Input: Latent dimension
    - 256  # Hidden layer
    - 512  # Hidden layer
    - 1024 # Hidden layer
    - 49152  # Output: Flattened image dimension (e.g., 28x28 for MNIST)

  discriminator_layers:
    - 49152  # Input: Flattened image dimension
    - 512  # Hidden layer
    - 256  # Hidden layer
    - 1    # Output: Single value representing probability image is real

  Optimizer:
    name: Adam
    params:
      lr: 0.0002
      betas: [0.5, 0.999]

  Scheduler:
    name: CosineAnnealingLR
    params:
      # Number of epochs before the learning rate is reset
      T_max: 10